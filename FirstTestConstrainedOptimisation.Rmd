---
title: "Testing constrained optimisation"
author: "Willem Vervoort"
date: "`r Sys.Date()`"
output: 
    pdf_document:
      fig_width: 7
      fig_height: 6
      fig_caption: true
---
```{r setup, warning=F, message=F}
# root dir
knitr::opts_knit$set(root.dir = "C:/Users/rver4657/ownCloud/working/Constr_optim")
knitr::opts_chunk$set(echo = TRUE)
# LOAD REQUIRED PACKAGES 
library(tidyverse)
library(zoo)
library(hydromad)
library(lattice)
```

# testing constrained optimisation in hydromad

The idea is to include a constraint on the normal optimisation objective function (such as NSE or RMSE). The constraint needs to be that the individual error (pointwise error) should not be $> \beta$, $\beta$ is a small number that will be optimised. In essence this is the same as a regularisation, but in this case we use the $\beta$ as a constraint.

# Hydromad standard fit

Load the hydromad Cotter data from the hydromad satellite project and fit GR4J using simple optimisation

```{r Cotterdata, fig.cap = "Standard hydromad fit using `FitByOptim()` on the Cotter data"}
# use the satellite hydromad example data
load("C:/Users/rver4657/ownCloud/working/SatelliteHydromad/Examples/Cotter.rdata")
load("C:/Users/rver4657/ownCloud/working/SatelliteHydromad/Examples/CotterMODISET.rdata")
#data(Cotter)


data.cal <- window(Cotter, start = "2000-01-01",
                   end = "2005-12-31")

# Define the model, important to define return_state=T
Cotter_mod <- hydromad(DATA=data.cal,
                       sma = "gr4j", routing = "gr4jrouting", 
                       x1 = c(100,1500), x2 = c(-30,20), 
                       x3 = c(5,500), 
                       x4 = c(0.5,10), etmult=c(0.01,0.5), 
                       return_state=TRUE)
# Fit traditional fit
# Using Optim algorithm for fitting
Cotter_fit_o<- fitByOptim(Cotter_mod,  
                          objective=~hmadstat("r.squared")(Q,X))
# Extract the coefficients and the summary
summary(Cotter_fit_o)
xyplot(Cotter_fit_o)
```


# A new objective function

Define a new objective function that includes the constraint, refit the Cotter test data, check against standard fit.

## defining the objective function

This might be the trickiest bit, as this requires introducing a parameter $\beta$, but also calibrate on this. Originally I wanted to rewrite the hydromad optimisation function, but I have started much easier by defining my own function that can be optimised using the standard optim function

```{r defineObjective}
objfun <- function(par, in_data, mod, ...) {
  # par is vector of initial values of parameters to be optimised
  # this includes beta
  # in_data are the input data
  # mod is a hydromad model
  mod_run <- update(mod, x1 = par[1], x2 = par[2], x3 = par[3], 
                         x4 = par[4], etmult=par[5])
  #browser()
  error <- fitted(mod_run) - in_data$Q
  
  adj_error <- abs(abs(error) - par[6])
  SSE <- sqrt(sum((error)^2,na.rm=T))/length(error)
  
  
  ValToMinimise <- SSE + sum((adj_error),na.rm=T)
  return(ValToMinimise)
}

test <- objfun(par=c(600, 0, 100, 2, 0.15, 5),
               mod=Cotter_mod,in_data=data.cal)
# this just tests whether the function can be loaded correctly
print(test) # the objective function value
```

## Calibrating the model
Now write an optimisation routine that includes this objective function and uses `optim()`. I am using the L-BFGS-B routine so I can constrain the upper and lower boundaries of the parameters as well. This is different from the constrained optimisation component.   

```{r boundaries}
# lower boundaries
# x1, x2, x3, x4, etmult, beta
lb <- c(100, -30, 5, 0.6 , 0.01, 0.1)
# upper boundaries
up <- c(1500, 20, 500, 10, 0.5, 10)

# initial values
par_in <- c(600, 0.1, 100, 2, 0.15, 5)
```

Note that $\beta$ is also fitted.  

Now fit the the actual model with the `optim()` routine.  

```{r fitConstrOptim, fig.cap = "Fit using the new constrained optimisation objective function using `Optim()` on the Cotter data"}
# use optim and L-BFGS-B
sol <- optim(par_in, objfun,method="L-BFGS-B", 
             in_data=data.cal, mod=Cotter_mod,
             lower = lb, upper = up)
# actual fit result for the parameters
sol$par

```

Here the parameter $\beta$ equals `r round(sol$par[6],4)`.  

## Inspect the results  
We can now inspect the results from the fit by looking at `sol`. But we also need to update the model and calculate the statistics

```{r Results_ConstrOptim}
# apply solution to model and plot
model_fit <- update(Cotter_mod, x1 = sol$par[1], x2 = sol$par[2], x3 = sol$par[3], 
                    x4 = sol$par[4], etmult=sol$par[5])
# make a plot
plot(fitted(model_fit))
lines(data.cal$Q,col="red")

# calculate statistics
hmadstat("rel.bias")(data.cal$Q[101:length(data.cal$Q)],
                     fitted(model_fit))
hmadstat("r.squared")(data.cal$Q[101:length(data.cal$Q)],
                      fitted(model_fit))
hmadstat("r.sq.sqrt")(data.cal$Q[101:length(data.cal$Q)],
                      fitted(model_fit))
hmadstat("r.sq.log")(data.cal$Q[101:length(data.cal$Q)],
                     fitted(model_fit))

```

This is slightly better in low flow fit and similar in r sq sqrt and has a lower bias then the original fit. That would be correct given the way we fit $\beta$, which will take away the focus from the high flows that the standard fit is causing.  

# Including Satellite data  

The next test would be to include the satellite data and to check if the fit on the satellite data improves relative to the hydromad satellite fit developed by Joseph Guillaume and myself: [SatelliteHydromad](https://github.com/WillemVervoort/SatelliteHydromad).  

## Satellite hydromad fit  
We start with simply using the functions in the satellite hydromad fitting example as we already have loaded the data. Here I am using the `SCEOptim()` function, which is slightly different from the basic `optim()`, but should get a fairly similar result.

First step is to prepare the data and load the functions from the satellite hydromad project.  

```{r PrepareDataFunctions}
# load functions from Satellite calibration
setwd("C:/Users/rver4657/ownCloud/working/SatelliteHydromad/Examples")
source("setup.R")

# using ETa.merge()
Flow.Modis.zoo <- ETa.merge(Flowdata=Cotter,ETdata=Cot_MODISET)

# remake the calibration data
data.modis.cal <- window(Flow.Modis.zoo, start = "2000-01-01",end = "2005-12-31")
```

We can now fit the model following the example in the github repository, and inspect the results and compare to the older results.  
```{r standardSatelliteFit, fig.cap = "Standard hydromad satellite data fit using FitBySCE() on Cotter and MODIS data"}
# Because we have rebuilt data.cal, redefine the model
Cotter_mod_M <- hydromad(DATA=data.modis.cal,
                         sma = "gr4j", routing = "gr4jrouting", 
                         x1 = c(100,1500), x2 = c(-30,20), 
                         x3 = c(5,500), x4 = c(0.5,10), 
                         etmult=c(0.01,0.5), 
                         return_state=TRUE)

Cotter_fit_q_ET <- FitMODbySCE(mod=Cotter_mod_M, FIT_Q=T, 
                    FIT_Q_ET = T, FIT_ET = T)
summary(Cotter_fit_q_ET, items = c("rel.bias", "r.squared","r.sq.sqrt", "r.sq.log"))
# essentially the same solution as earlier, ET calibration has no effect
# plot
xyplot(Cotter_fit_q_ET)
```

These results and statistics suggests there is little difference between fitting with ET and fitting without ET for this catchment, as I have earlier shown with the SWAT results. The question is whether this will change with the constrained optimisation.  

But that is only the fit on Q that is shown, and the statistics calculated. We actually want to know the fit on ET for the last fit in the table. There is a little trick here, as the ET data need to be aggregated back to the 8 day periods of the original data. In other words, we need a function that calculates the NSE stat, but on the aggregated data.

Using the `plot.ET()` function these zero values are automatically removed.  

```{r HydromadFitETResults, fig.cap = "Fit of the model to the MODIS ET data using the standard hydromad fit"}
aET_obs <- aggregate(data.modis.cal$aET,
                     list(date=data.modis.cal$et.period),sum)
ET_pred <- aggregate(Cotter_fit_q_ET[["Fit ET and Q"]]$U$ET,
                     list(date=data.modis.cal$et.period),
                      sum)

nseStat(coredata(aET_obs),coredata(ET_pred))

# now make a plot using the plot.ET() function
plot.ET(data.modis.cal,Cotter_fit_q_ET[["Fit ET and Q"]])
```

## fitting the constrained optimisation  
For this we need to rewrite the whole optimisation function to include ET. I will be making use of some of the functions from the satellite hydromad. The first step is to once again define a function to fit with `optim()`.  For this we need to have the objective function being a function of beta and the error, similar to the example above with just the Q data.

```{r DefineObjectiveET}
objfun <- function(par, in_data, mod, ...) {
  # par is vector of initial values of parameters to be optimised
  # this includes beta
  # in_data are the input data, which includes MODIS ET
  # mod is a hydromad model
  mod_run <- update(mod, x1 = par[1], x2 = par[2], x3 = par[3], 
                    x4 = par[4], etmult=par[5])
  #browser()
  # Q objective functions
  error_Q <- fitted(mod_run) - in_data$Q
  
  adj_error_Q <- abs(abs(error_Q) - par[6])
  SSE_Q <- sqrt(sum((error_Q)^2,na.rm=T))/length(error_Q)
  # ET objective function
  # aggregate the ET data to the 8 day totals
  aET_fin <- aggregate(in_data$aET,list(date=in_data$et.period),sum)
  ET_fin <- aggregate(mod_run$U$ET,
                      list(date=in_data$et.period),
                      sum)
  #browser()
  error_ET <- coredata(ET_fin) - coredata(aET_fin)
  
  adj_error_ET <- abs(abs(error_ET) - par[6])
  SSE_ET <- sqrt(sum((error_ET)^2,na.rm=T))/length(error_ET)
  
  # initially set w = 0.5
  w <- 0.5 # can we in some way set this to SSE_ET/SSE_Q?
  
  ValToMinimise <- w*(SSE_Q + sum((adj_error_Q),na.rm=T)) +
                   (1-w)*(SSE_ET + sum((adj_error_ET),na.rm=T))
  return(ValToMinimise)
}

test_QET <- objfun(par=c(600, 0, 100, 2, 0.15, 5),
               mod=Cotter_mod_M,in_data=data.modis.cal)
# again, just test if the function is loaded correctly
```

Using the boundaries already defined earlier, the model can now be fitted to both ET and Q using constrained optimisation to both.

```{r ConstrainedOptimET}
# use optim and L-BFGS-B
sol <- optim(par_in, objfun,method="L-BFGS-B", 
             in_data=data.modis.cal, mod=Cotter_mod_M,
             lower = lb, upper = up)
# sol$par should be the results
sol$par
```

Here the parameter $\beta$ equals `r round(sol$par[6],4)`.  

## Inspect the ET fit results  
Similar to the earlier calibration the model needs to be updated to calculate the statistics.  

```{r Results_ConstrOptimET}
# apply solution to model and plot
model_fit_M <- update(Cotter_mod_M, x1 = sol$par[1], x2 = sol$par[2], x3 = sol$par[3], 
                    x4 = sol$par[4], etmult=sol$par[5])
# make a plot
plot(fitted(model_fit_M))
lines(data.modis.cal$Q,col="red")

# calculate statistics
nseStat(data.modis.cal$Q,fitted(model_fit_M))
hmadstat("rel.bias")(data.modis.cal$Q[101:length(data.modis.cal$Q)],
                     fitted(model_fit_M))
hmadstat("r.squared")(data.modis.cal$Q[101:length(data.modis.cal$Q)],
                      fitted(model_fit_M))
hmadstat("r.sq.sqrt")(data.modis.cal$Q[101:length(data.modis.cal$Q)],
                      fitted(model_fit_M))
hmadstat("r.sq.log")(data.modis.cal$Q[101:length(data.modis.cal$Q)],
                     fitted(model_fit_M))
```

This suggests the actual calibration has again reduced the influence on the peaks and the calibration on Q is reduced compared to calibration on Q alone. And compared to the unconstrained calibration, the calibration on Q has decreased, but is still similar in the low and overall flow (`r.sq.log` and `r.sq.sqrt`).

We can also recalculate the fit on ET using the model output. Again, I am removing the zero values to calculate the correct NSE for the calibration on ET.

```{r ConstroptimFitETResults, fig.cap = "Fit of the model to the MODIS ET data using the constrained optimisation"}
# summarise ET to 8 day values
aET_obs <- aggregate(data.modis.cal$aET,
                     list(date=data.modis.cal$et.period),sum)
ET_pred <- aggregate(model_fit_M$U$ET,
                     list(date=data.modis.cal$et.period),
                      sum)

nseStat(coredata(aET_obs),coredata(ET_pred))

plot.ET(caldata=data.modis.cal,model_fit_M)
```

This shows again improved the low flow and general flow calibration, reduced the peaks and surprisingly a reduced ET calibration. This could be to the value of w that I assigned, but some testing with this didn't seem to make any difference.

It could be because $\beta$ should be different for Q and ET, and therefore I need to possibly calibrate on two different $\beta$ values.

Finally, the model is not spatial, so it is not really taking advantage of the ET data features. This needs to be further tested with SWAT.  